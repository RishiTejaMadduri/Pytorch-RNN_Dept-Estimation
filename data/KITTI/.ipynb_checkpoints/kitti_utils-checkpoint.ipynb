{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pykitti\n",
    "import sys\n",
    "from collections import Counter, namedtuple\n",
    "from scipy.interpolate import LinearNDInterpolator\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def depth_read(filename):\n",
    "    # loads depth map D from png file\n",
    "    # and returns it as a numpy array,\n",
    "    # for details see readme.txt\n",
    "    depth_png=np.array(Image.open(filename), dtype=int)\n",
    "    # make sure we have a proper 16bit depth map here.. not 8bit!\n",
    "    assert(np.max(depth_png)>255)\n",
    "    \n",
    "    depth=depth_png.astype(np.float)/256\n",
    "    \n",
    "    depth[depth_png==0]=-1\n",
    "    \n",
    "    return depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def long_image_kitti(views, max_views_num):\n",
    "    height=views[0].image.shape[0]\n",
    "    width=views[0].image.shape[1]\n",
    "    total_width=width*max_views_num\n",
    "    new_im=np.zeros((height,total_width,3), dtype=np.uint8)\n",
    "    new_depth = np.zeros((height, total_width), dtype=np.float32)\n",
    "    new_motion = np.zeros((4, 4 * max_views_num), dtype=np.float32)\n",
    "    x_offset = 0\n",
    "    RT_offset = 0\n",
    "    \n",
    "    for view in views:\n",
    "        new_im[:, x_offset:x_offset + width, :] = view.image\n",
    "        new_depth[:, x_offset:x_offset + width] = view.depth\n",
    "        x_offset += width\n",
    "\n",
    "        new_motion[:, RT_offset:RT_offset + 4] = np.reshape(view.P, (4, 4))\n",
    "        RT_offset += 4\n",
    "\n",
    "    return new_im, new_depth, new_motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin_interp(shape, xyd):\n",
    "    # taken from https://github.com/hunse/kitti\n",
    "    m, n = shape\n",
    "    ij, d = xyd[:, 1::-1], xyd[:, 2]\n",
    "    f = LinearNDInterpolator(ij, d, fill_value=0) #Lookup interpolaion\n",
    "    J, I = np.meshgrid(np.arange(n), np.arange(m))\n",
    "    IJ = np.vstack([I.flatten(), J.flatten()]).T\n",
    "    disparity = f(IJ).reshape(shape)\n",
    "    return disparity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub2ind(matrixSize, rowSub, colSub):\n",
    "    m, n = matrixSize\n",
    "    return rowSub * (n-1) + colSub - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_depth_map(P_velo2im, velo, im_shape, interp=False, vel_depth=False):\n",
    "\n",
    "    # load velodyne points and remove all behind image plane (approximation)\n",
    "    # each row of the velodyne data is forward, left, up, reflectance\n",
    "    #import pdb;pdb.set_trace()\n",
    "    velo = velo[velo[:, 2] >= 0, :]\n",
    "    velo[:, 3] = 1.0\n",
    "\n",
    "    #import pdb;pdb.set_trace()\n",
    "    # project the points to the camera\n",
    "    velo_pts_im = np.dot(P_velo2im, velo.T).T\n",
    "\n",
    "    velo_pts_im[:, :2] = velo_pts_im[:,:2] / velo_pts_im[:,2][..., np.newaxis]\n",
    "\n",
    "    if vel_depth:\n",
    "        velo_pts_im[:, 2] = velo[:, 0]\n",
    "\n",
    "    # check if in bounds\n",
    "    # use minus 1 to get the exact same value as KITTI matlab code\n",
    "    #velo_pts_im[:, 0] = np.round(velo_pts_im[:,0]) - 1\n",
    "    #velo_pts_im[:, 1] = np.round(velo_pts_im[:,1]) - 1\n",
    "    val_inds = (velo_pts_im[:, 0] >= 0) & (velo_pts_im[:, 1] >= 0)\n",
    "    val_inds = val_inds & (velo_pts_im[:,0] < im_shape[1]) & (velo_pts_im[:,1] < im_shape[0])\n",
    "    velo_pts_im = velo_pts_im[val_inds, :]\n",
    "\n",
    "    # project to image\n",
    "    depth = np.zeros((im_shape))\n",
    "    depth[velo_pts_im[:, 1].astype(np.int), velo_pts_im[:, 0].astype(np.int)] = velo_pts_im[:, 2]\n",
    "\n",
    "\n",
    "    # find the duplicate points and choose the closest depth\n",
    "    inds = sub2ind(depth.shape, velo_pts_im[:, 1], velo_pts_im[:, 0])\n",
    "    dupe_inds = [item for item, count in Counter(inds).items() if count > 1]\n",
    "    for dd in dupe_inds:\n",
    "        pts = np.where(inds==dd)[0]\n",
    "        x_loc = int(velo_pts_im[pts[0], 0])\n",
    "        y_loc = int(velo_pts_im[pts[0], 1])\n",
    "        depth[y_loc, x_loc] = velo_pts_im[pts, 2].min()\n",
    "    depth[depth<0] = 0\n",
    "\n",
    "    if interp:\n",
    "        # interpolate the depth map to fill in holes\n",
    "        depth_interp = lin_interp(im_shape, velo_pts_im)\n",
    "        #plt.imsave(\"test.png\", depth_interp, cmap='plasma')\n",
    "        return depth, depth_interp\n",
    "    else:\n",
    "        return depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_grid(width,height,fx,fy,cx,cy):\n",
    "    return np.meshgrid(\n",
    "      (np.arange(width)  - cx) / fx,\n",
    "      (np.arange(height) - cy) / fy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_surface(z, width, height,fx,fy, cx, cy):\n",
    "    S = np.dstack((get_image_grid(width, height,fx,fy, cx, cy) + [np.ones_like(z)])) * z[:,:,np.newaxis]\n",
    "    pad = np.ones_like(z)\n",
    "    return np.dstack([S]+[pad]).reshape([-1,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image_depth_from_idx(dataset,idx,resizedwidth,resizedheight):\n",
    "    image = cv2.resize(np.array(dataset.get_cam3(idx)),(resizedwidth,resizedheight))\n",
    "    #velo = dataset.get_velo(idx)\n",
    "    pose =  np.dot(dataset.calib.T_cam3_imu, dataset.oxts[idx].T_w_imu)\n",
    "    #import pdb;pdb.set_trace()\n",
    "    #depth = generate_depth_map(np.dot(dataset.calib.P_rect_20,dataset.calib.T_cam2_velo), velo, image.shape[:2])\n",
    "    return image,pose#,depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_samples_from_sequence_kitti(output_dir, kitti_path, depth_path,seq_name, max_views_num=10):\n",
    "    \"\"\"Read a KITTI sequence and create a npy file\n",
    "        \n",
    "        kitti_path-Path where Kitti sequences are stored \n",
    "        \n",
    "        seq_name= 20xxx_xx_xx_sync\n",
    "        \n",
    "        returns the number of generated group\n",
    "        \"\"\"\n",
    "\t\n",
    "    resizedheight=128\n",
    "    resizedwidth=416\n",
    "    date=seq_name[:10]\n",
    "    drive=seq_name[-9:-5]\n",
    "    generated_groups=0\n",
    "   \n",
    "    dataset = pykitti.raw(kitti_path, date, drive)\n",
    "    #A tuple to store information for each view\n",
    "    View_kitti = namedtuple('View', {'P', 'K', 'image', 'depth'})\n",
    "    \n",
    "    intrinsics_ori = dataset.calib.K_cam3\n",
    "    dataset.calib.P_rect_30[0,3] *= 0#(resizedwidth / 1600)\n",
    "    dataset.calib.P_rect_30[1,3] *= 0#(resizedheight / 375)\n",
    "    dataset.calib.P_rect_30[2,3] *= 0\n",
    "    \n",
    "    if len(dataset.velo_files)<=0:\n",
    "        return 0\n",
    "\n",
    "    image = np.array(dataset.get_cam3(0))\n",
    "\n",
    "    ori_height, ori_width = image.shape[:2]\n",
    "\n",
    "\n",
    "    intrinsics = intrinsics_ori.copy()\n",
    "    intrinsics[0, 0] = intrinsics_ori[0, 0] * resizedwidth / ori_width\n",
    "    intrinsics[0, 2] = intrinsics_ori[0, 2] * resizedwidth / ori_width\n",
    "    intrinsics[1, 1] = intrinsics_ori[1, 1] * resizedheight / ori_height\n",
    "    intrinsics[1, 2] = intrinsics_ori[1, 2] * resizedheight / ori_height\n",
    "\n",
    "#     import pdb;pdb.set_trace()\n",
    "\n",
    "    homo_intrinsic = np.concatenate([intrinsics,np.zeros([3,1])],axis=1)\n",
    "    homo_intrinsic = np.concatenate([homo_intrinsic,np.zeros([1,4])],axis=0)\n",
    "    homo_intrinsic[3,3]=1.0\n",
    "    mean_baseline = []\n",
    "    \n",
    "    for idx in range(len(dataset.velo_files)):\n",
    "\n",
    "\n",
    "        file = dataset.cam3_files[idx].split('/')[-1]\n",
    "        depth_file = os.path.join(depth_path,seq_name,'proj_depth','groundtruth','image_03',file)\n",
    "        if not os.path.isfile(depth_file):\n",
    "            continue\n",
    "\n",
    "        image, pose = read_image_depth_from_idx(dataset,idx, resizedwidth, resizedheight)\n",
    "        #import pdb;pdb.set_trace()\n",
    "        depth = depth_read(depth_file)\n",
    "        S = generate_surface(depth,ori_width,ori_height,intrinsics_ori[0, 0],intrinsics_ori[1, 1],intrinsics_ori[0, 2],intrinsics_ori[1, 2])\n",
    "        depth = generate_depth_map(homo_intrinsic, S, image.shape[:2])\n",
    "\n",
    "        # import pdb;pdb.set_trace()\n",
    "        # plt.imsave(\"image2.png\", image)\n",
    "        # plt.imsave(\"depth2.png\", depth, cmap='plasma')\n",
    "\n",
    "        view1 = View_kitti(P=pose, K=intrinsics, image=image, depth=depth)\n",
    "        views = [view1]\n",
    "\n",
    "        T_pre = pose[0:3,3]\n",
    "        R_pre = pose[0:3,0:3]\n",
    "\n",
    "        #If there is no more than 10 images afterwards, we stop\n",
    "        if(idx+9>=len(dataset.velo_files)):\n",
    "            break\n",
    "            \n",
    "        for idx2 in range(idx+1,len(dataset.velo_files)):\n",
    "\n",
    "            file = dataset.cam3_files[idx2].split('/')[-1]\n",
    "            depth_file = os.path.join(depth_path,seq_name,'proj_depth','groundtruth','image_03',file)\n",
    "            if not os.path.isfile(depth_file):\n",
    "                continue\n",
    "\n",
    "            image, pose = read_image_depth_from_idx(dataset,idx2, resizedwidth, resizedheight)\n",
    "            depth = depth_read(depth_file)\n",
    "            S = generate_surface(depth,ori_width,ori_height,intrinsics_ori[0, 0],intrinsics_ori[1, 1],intrinsics_ori[0, 2],intrinsics_ori[1, 2])\n",
    "            depth = generate_depth_map(homo_intrinsic, S, image.shape[:2])\n",
    "\n",
    "            #Check whether the scene is static\n",
    "            T_curr = pose[0:3,3]\n",
    "            R_curr = pose[0:3,0:3]\n",
    "            baseline = np.linalg.norm((-R_pre.transpose().dot(T_pre)) - (-R_curr.transpose().dot(T_curr)))\n",
    "            #import pdb;pdb.set_trace()\n",
    "            if baseline < 0.3:\n",
    "                continue\n",
    "\n",
    "            mean_baseline.append(baseline)\n",
    "\n",
    "            T_pre = T_curr\n",
    "            R_pre = R_curr\n",
    "\n",
    "            view2 = View_kitti(P=pose, K=intrinsics, image=image, depth=depth)\n",
    "            views.append(view2)\n",
    "\n",
    "            if len(views) == max_views_num:\n",
    "                break\n",
    "\n",
    "        if len(views)==max_views_num:\n",
    "            concat_view,concat_depth,concat_motion = long_image_kitti(views,max_views_num)\n",
    "            keys=['image_seq', 'depth_seq', 'motion_seq', 'intrinsics']\n",
    "            ele_list=[concat_view,concat_depth,concat_motion, intrinsics]\n",
    "            print(ele_list[0].size)\n",
    "#             print(len(keys))  \n",
    "            example=dict(zip(keys,ele_list))\n",
    "            filename='cam3_'+ seq_name + \".pickle\"\n",
    "\n",
    "            with open(filename,'wb') as f:\n",
    "                pickle.dump(example,f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            #outfile.close()\n",
    "            generated_groups+=1\n",
    "\n",
    "    print(np.mean(mean_baseline))\n",
    "    return generated_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
