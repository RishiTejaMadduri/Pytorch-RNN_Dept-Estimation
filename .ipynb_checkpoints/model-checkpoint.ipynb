{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import BasicConvLSTMCell\n",
    "\n",
    "import torchvision\n",
    "DISP_SCALING_RESNET50 = 10.0\n",
    "MIN_DISP = 0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_like(inputs,ref):\n",
    "    assert(input.size(2) >= ref.size(2) and input.size(3) >= ref.size(3))\n",
    "    \n",
    "    return input[:, :, :ref.size(2), :ref.size(3)]\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convLSTM(input, hidden, filters, kernel, scope):\n",
    "    cell = BasicConvLSTMCell.BasicConvLSTMCell([input.shape[1], input.shape[2]], kernel, filters)\n",
    "    \n",
    "    if hidden is None:\n",
    "        hidden=cell.zero_state(input.shape[0]).float()\n",
    "    \n",
    "    y_, hideen=cell(input, hidden)\n",
    "    \n",
    "    return y_, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_depth(in_planes):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_planes, 1, kernel_size = 1, padding = 1),\n",
    "        nn.Sigmoid()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(in_planes, out_planes, kernel_size = 3, stride = 2):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_planes, out_planes, kernel_size = kernel_size, padding=(kernel_size-1)//2, stride = stride),\n",
    "        nn.BatchNorm2d(out_planes),\n",
    "        nn.ReLU(inplace = True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Iconv(in_planes, out_planes):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_place, out_planes, kernel_size = 3, padding = 1),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_conv(in_planes, out_planes, kernel_size = 3):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_planes, out_planes, kernel_size = kernel_size, stride = 2, padding = (kernel_size - 1)//2),\n",
    "        nn.Relu(inplace = True),\n",
    "        nn.BatchNorm2d(out_planes),\n",
    "        nn.Conv2d(out_planes, out_planes, kernel_size = kernel_size, padding = (kernel_size - 1)//2),\n",
    "        nn.Relu(inplace = True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upconv(in_planes, out_planes):\n",
    "    return nn.Sequential(\n",
    "        nn.ConvTranspose2d(in_planes, out_planes, kernel_size = 3, stride = 2, padding = 1, output_padding = 1),\n",
    "        nn.ReLU(inplace =  True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class rnn_depth_net_encoderlstm():\n",
    "    \n",
    "    def __init__(self, current_input, hidden_state):\n",
    "        super(rnn_depth_net_encoderlstm, self).__init__()\n",
    "        \n",
    "        H = current_input.shape[1]\n",
    "        W = current_input.shape[2]\n",
    "        \n",
    "        conv_planes = [32, 64, 128, 256, 256, 256, 512]\n",
    "        \n",
    "        self.conv1 = downsample_conv(3, conv_planes[0], kernel_size = 7)\n",
    "        self.conv2 = downsample_conv(conv_planes[0], conv_planes[1], kernel_size = 5)\n",
    "        self.conv3 = down_sample_conv(conv_planes[1], conv_planes[2])\n",
    "        self.conv4 = down_sample_conv(conv_planes[2], conv_planes[3])\n",
    "        self.conv5 = down_sample_conv(conv_planes[3], conv_planes[4])\n",
    "        self.conv6 = down_sample_conv(conv_planes[4], conv_planes[5])\n",
    "        self.conv7 = down_sample_conv(conv_planes[5], conv_planes[6])\n",
    "        \n",
    "        upconv_planes = [256, 128, 128, 128, 64, 32, 16]\n",
    "        \n",
    "        self.upconv7 = upconv(conv_planes[6], upconv_planes[0])\n",
    "        self.upconv6 = upconv(conv_planes[0], upconv_planes[1])\n",
    "        self.upconv5 = upconv(conv_planes[1], upconv_planes[2])\n",
    "        self.upconv4 = upconv(conv_planes[2], upconv_planes[3])\n",
    "        self.upconv3 = upconv(conv_planes[3], upconv_planes[4])\n",
    "        self.upconv2 = upconv(conv_planes[4], upconv_planes[5])\n",
    "        self.upconv1 = upconv(conv_planes[5], upconv_planes[6])\n",
    "        \n",
    "        self.iconv7 = Iconv(input,256)\n",
    "        self.iconv6 = Iconv(input, 128)\n",
    "        self.iconv5 = Iconv(input, 128)\n",
    "        self.iconv4 = Iconv(input, 128)\n",
    "        self.iconv3 = Iconv(input, 64)\n",
    "        self.iconv2 = Iconv(input, 32)\n",
    "        self.iconv1 = Iconv(input, 16)\n",
    "        \n",
    "        depth = pred_depth(16)\n",
    "        #try putting input instead of out_conv# incase you get dimension error\n",
    "        def forward(self, current_input, hidden_state):\n",
    "            out_conv1 = self.conv1(current_input)\n",
    "            out_conv1b, hidden1 = convLSTM(out_conv1, hidden_state[0], 32, [3,3])\n",
    "            out_conv2 = self.conv2(out_conv1b)\n",
    "            out_conv2b, hidden2 = convLSTM(out_conv2, hidden_state[1], 64, [3,3])\n",
    "            out_conv3 = self.conv3(out_conv2b)\n",
    "            out_conv3b, hidden3 = convLSTM(out_conv3, hidden_state[2], 128, [3,3])\n",
    "            out_conv4 = self.conv4(out_conv3b)\n",
    "            out_conv4b, hidden4 = convLSTM(out_conv4, hidden_state[3], 256, [3,3])\n",
    "            out_conv5 = self.conv5(out_conv4b)\n",
    "            out_conv5b, hidden5 = convLSTM(out_conv5, hidden_state[4], 256, [3,3])\n",
    "            out_conv6 = self.conv6(out_conv5b)\n",
    "            out_conv6b, hidden6 = convLSTM(out_conv6, hidden_state[5], 256, [3,3])\n",
    "            out_conv7 = self.conv7(out_conv6b)\n",
    "            out_conv7b, hidden7 = convLSTM(out_conv7, hidden_state[6], 512, [3,3])\n",
    "            \n",
    "            out_upconv7 = self.upconv7(out_conv7b)\n",
    "            out_upconv7 = resize_like(out_upconv7, out_conv6b)\n",
    "            i7_in = torch.cat((out_upconv7, conv6b), dim=3)\n",
    "            out_iconv7 = self.iconv7(i7_in)\n",
    "            \n",
    "            out_upconv6 = self.upconv6(out_iconv7)\n",
    "            out_upconv6 = resize_like(out_upconv6, out_conv5b)\n",
    "            i6_in = torch.cat((out_upconv6, conv5b), dim=3)\n",
    "            out_iconv6 = self.iconv6(i6_in)\n",
    "            \n",
    "            out_upconv5 = self.upconv5(out_iconv6)\n",
    "            out_upconv5 = resize_like(out_upconv5, out_conv4b)\n",
    "            i5_in = torch.cat((out_upconv5, conv4b), dim=3)\n",
    "            out_iconv5 = self.iconv5(i5_in)\n",
    "            \n",
    "            out_upconv4 = self.upconv6(out_iconv5)\n",
    "            out_upconv4 = resize_like(out_upconv4, out_conv3b)\n",
    "            i4_in = torch.cat((out_upconv4, conv3b), dim=3)\n",
    "            out_iconv4 = self.iconv4(i4_in)\n",
    "            \n",
    "            out_upconv3 = self.upconv3(out_iconv4)\n",
    "            out_upconv3 = resize_like(out_upconv3, out_conv2b)\n",
    "            i3_in = torch.cat((out_upconv3, conv2b), dim=3)\n",
    "            out_iconv3 = self.iconv3(i3_in)\n",
    "            \n",
    "            out_upconv2 = self.upconv2(out_iconv3)\n",
    "            out_upconv2 = resize_like(out_upconv2, out_conv1b)\n",
    "            i2_in = torch.cat((out_upconv2, conv1b), dim=3)\n",
    "            out_iconv2 = self.iconv2(i2_in)\n",
    "            \n",
    "            out_upconv1 = self.upconv1(out_iconv2)\n",
    "            out_iconv1 = self.iconv1(out_upconv1)\n",
    "            \n",
    "            out_depth = self.depth(out_iconv1)*DISP_SCALING_RESNET50+MIN_DISP\n",
    "            \n",
    "            return depth, [hidden1, hidden2, hidden3, hidden4, hidden5, hidden6, hidden7]\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pose_net(nn.Module):\n",
    "    \n",
    "    def __init__(self, posenet_inputs, hidden_state):\n",
    "        super(pose_net, self).__init__()\n",
    "        \n",
    "        conv_planes = [16, 16, 64, 128, 256, 256, 256, 512]\n",
    "        self.conv1 = conv(3, conv_planes[0], kernel_size = 7)\n",
    "        self.conv2 = conv(conv_planes[0], conv_planes[1])\n",
    "        self.conv3 = conv(conv_planes[1], conv_planes[2])\n",
    "        self.conv4 = conv(conv_planes[2], conv_planes[3])\n",
    "        self.conv5 = conv(conv_planes[3], conv_planes[4])\n",
    "        self.conv6 = conv(conv_planes[4], conv_planes[5])\n",
    "        self.conv7 = conv(conv_planes[6], conv_planes[7])\n",
    "        self.pose_pred = nn.Conv2d(conv_planes[6], 6, kernel_size = 1)\n",
    "        \n",
    "    def forward(self, posnet_inputs, hidden_states):\n",
    "        out_conv1 = self.conv1(posnet_inputs)\n",
    "        out_conv1b, hidden1 = convLSTM(out_conv1, hidden_state[0], 16, 3)\n",
    "        out_conv2 = self.conv2(out_conv1b)\n",
    "        out_conv2b, hidden2 = convLSTM(out_conv2, hidden_state[1], 64, 3)\n",
    "        out_conv3 = self.conv3(out_conv2b)\n",
    "        out_conv3b, hidden3 = convLSTM(out_conv3, hidden_state[2], 128, 3)\n",
    "        out_conv4 = self.conv4(out_conv3b)\n",
    "        out_conv4b, hidden4 = convLSTM(out_conv4, hidden_state[3], 256, 3)\n",
    "        out_conv5 = self.conv5(out_conv4b)\n",
    "        out_conv5b, hidden5 = convLSTM(out_conv5, hidden_state[4], 256, 3)\n",
    "        out_conv6 = self.conv6(out_conv5b)\n",
    "        out_conv6b, hidden6 = convLSTM(out_conv6, hidden_state[5], 256, 3)\n",
    "        out_conv7 = self.conv7(out_conv6b)\n",
    "        out_conv7b, hidden7 = convLSTM(out_conv7, hidden_state[6], 512, 3)\n",
    "        pose = self.pose_pred(out_conv7b)\n",
    "        pose_avg = pose.mean(3).mean(2)\n",
    "        pose_final = torch.reshape(pose_avg, [-1, 6])*0.01\n",
    "        \n",
    "        return pose_final,[hidden1, hidden2, hidden3, hidden4, hidden5, hidden6, hidden7]  \n",
    "    \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
